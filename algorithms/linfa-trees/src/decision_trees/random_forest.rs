//! Random Forest Classifier
//!
//! An ensemble of decision trees trained on bootstrapped, feature‐subsampled slices of the data.

use linfa::prelude::*;
use linfa::{error::Error, Float, ParamGuard};
use ndarray::{Array1, Array2, Axis};
use rand::{rngs::StdRng, seq::index::sample, Rng, SeedableRng};
use std::marker::PhantomData;

use super::algorithm::DecisionTree;

#[derive(Debug, Clone)]
pub struct RandomForestClassifier<F: Float> {
    trees: Vec<DecisionTree<F, usize>>,
    feature_indices: Vec<Vec<usize>>,
    _phantom: PhantomData<F>,
}

#[derive(Debug, Clone)]
pub struct RandomForestParams<F: Float> {
    inner: RandomForestValidParams<F>,
}

#[derive(Debug, Clone)]
pub struct RandomForestValidParams<F: Float> {
    pub n_trees: usize,
    pub max_depth: Option<usize>,
    pub feature_subsample: f32,
    pub seed: u64,
    _phantom: PhantomData<F>,
}

impl<F: Float> RandomForestParams<F> {
    /// Create a new random forest with the specified number of trees.
    pub fn new(n_trees: usize) -> Self {
        Self {
            inner: RandomForestValidParams {
                n_trees,
                max_depth: None,
                feature_subsample: 1.0,
                seed: 42,
                _phantom: PhantomData,
            },
        }
    }

    /// Set the maximum depth of each tree.
    pub fn max_depth(mut self, depth: Option<usize>) -> Self {
        self.inner.max_depth = depth;
        self
    }

    /// Fraction of features to sample per tree (0.0–1.0).
    pub fn feature_subsample(mut self, ratio: f32) -> Self {
        self.inner.feature_subsample = ratio;
        self
    }

    /// RNG seed for reproducibility.
    pub fn seed(mut self, seed: u64) -> Self {
        self.inner.seed = seed;
        self
    }
}

impl<F: Float> ParamGuard for RandomForestParams<F> {
    type Checked = RandomForestValidParams<F>;
    type Error = Error;

    fn check_ref(&self) -> Result<&Self::Checked, Self::Error> {
        if self.inner.n_trees == 0 {
            return Err(Error::Parameters("n_trees must be > 0".into()));
        }
        if !(0.0..=1.0).contains(&self.inner.feature_subsample) {
            return Err(Error::Parameters(
                "feature_subsample must be in [0, 1]".into(),
            ));
        }
        Ok(&self.inner)
    }

    fn check(self) -> Result<Self::Checked, Self::Error> {
        self.check_ref()?;
        Ok(self.inner)
    }
}

/// Bootstrap‐sample the dataset with replacement.
fn bootstrap<F: Float>(
    dataset: &DatasetBase<Array2<F>, Array1<usize>>,
    rng: &mut impl Rng,
) -> DatasetBase<Array2<F>, Array1<usize>> {
    let n = dataset.nsamples();
    let indices: Vec<usize> = (0..n).map(|_| rng.gen_range(0..n)).collect();
    let rec = dataset.records.select(Axis(0), &indices);
    let tgt = dataset.targets.select(Axis(0), &indices);
    Dataset::new(rec, tgt)
}

impl<F: Float + Send + Sync> Fit<Array2<F>, Array1<usize>, Error> for RandomForestValidParams<F> {
    type Object = RandomForestClassifier<F>;

    fn fit(&self, dataset: &DatasetBase<Array2<F>, Array1<usize>>) -> Result<Self::Object, Error> {
        let mut rng = StdRng::seed_from_u64(self.seed);
        let mut trees = Vec::with_capacity(self.n_trees);
        let mut feats_list = Vec::with_capacity(self.n_trees);

        let n_features = dataset.records.ncols();
        let n_sub = ((n_features as f32) * self.feature_subsample).ceil() as usize;

        for _ in 0..self.n_trees {
            // 1) Bootstrap rows
            let sample_set = bootstrap(dataset, &mut rng);

            // 2) Random feature subset
            let feats = sample(&mut rng, n_features, n_sub)
                .into_iter()
                .collect::<Vec<_>>();
            feats_list.push(feats.clone());

            // 3) Train a tree on that feature slice
            let sub_rec = sample_set.records.select(Axis(1), &feats);
            let sub_ds = Dataset::new(sub_rec, sample_set.targets.clone());
            let tree = DecisionTree::params()
                .max_depth(self.max_depth)
                .fit(&sub_ds)?;
            trees.push(tree);
        }

        Ok(RandomForestClassifier {
            trees,
            feature_indices: feats_list,
            _phantom: PhantomData,
        })
    }
}

impl<F: Float> Predict<Array2<F>, Array1<usize>> for RandomForestClassifier<F> {
    fn predict(&self, x: Array2<F>) -> Array1<usize> {
        let n = x.nrows();
        // adjust 100 to the expected number of classes if known
        let mut votes = vec![vec![0; n]; 100];

        for (tree, feats) in self.trees.iter().zip(&self.feature_indices) {
            // Slice test data to the features this tree saw
            let sub_x = x.select(Axis(1), feats);
            let preds: Array1<usize> = tree.predict(&sub_x);
            for (i, &c) in preds.iter().enumerate() {
                votes[c][i] += 1;
            }
        }

        // Majority vote per sample
        Array1::from(
            (0..n)
                .map(|i| {
                    votes
                        .iter()
                        .enumerate()
                        .max_by_key(|(_, v)| v[i])
                        .map(|(lbl, _)| lbl)
                        .unwrap_or(0)
                })
                .collect::<Vec<_>>(),
        )
    }
}
